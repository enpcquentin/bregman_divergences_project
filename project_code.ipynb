{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with Bregman Divergences : Project\n",
    "## Duchemin Quentin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) RL algorithms using KL divergence as approximation of Mirror Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from renderer import *\n",
    "from gridworld import *\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = [\n",
    "    ['', '', '', 1],\n",
    "    ['', 'x', '', -1],\n",
    "    ['', '', '', '']\n",
    "]\n",
    "\n",
    "env = GridWorld(gamma=0.95, grid=grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self,pi):\n",
    "        n_states,n_actions = np.shape(pi)\n",
    "        self.n_actions = n_actions\n",
    "        self.n_states = n_states\n",
    "        self.pi = pi\n",
    "    def draw_action(self,state):\n",
    "        u = np.random.rand()\n",
    "        probas = np.cumsum(self.pi[state,:])\n",
    "        a = 0\n",
    "        while (a < self.n_actions-1 and (u > probas[a] or self.pi[state,a]==0)):\n",
    "            a += 1\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLModel:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def initialize_pi(self):\n",
    "        pi = np.zeros((self.env.n_states,self.env.n_actions))\n",
    "        for s in range(self.env.n_states):\n",
    "            actions = self.env.state_actions[s]\n",
    "            for a in actions:\n",
    "                pi[s,a] = 1./len(actions)\n",
    "        return pi\n",
    "    \n",
    "    def collect_episodes(self, policy=None, horizon=None, n_episodes=1, render=False):\n",
    "        paths = []\n",
    "\n",
    "        for _ in range(n_episodes):\n",
    "            observations = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            next_states = []\n",
    "            ep_r = 0\n",
    "            state = self.env.reset()\n",
    "            for _ in range(horizon):\n",
    "                action = policy.draw_action(state)\n",
    "                next_state, reward, terminal = self.env.step(state,action)\n",
    "                ep_r += reward\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                observations.append(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                next_states.append(next_state)\n",
    "                state = copy.copy(next_state)\n",
    "                if terminal:\n",
    "                    if len(self.moving_rewards) == 0:  # record running episode reward\n",
    "                        self.moving_rewards.append(ep_r)\n",
    "                    else:\n",
    "                        self.moving_rewards.append(0.9 * self.moving_rewards[-1] + 0.1 * ep_r)\n",
    "                    # Finish rollout if terminal state reached\n",
    "                    break\n",
    "                    # We need to compute the empirical return for each time step along the\n",
    "                    # trajectory\n",
    "            paths.append(dict(\n",
    "                states=np.array(observations),\n",
    "                actions=np.array(actions),\n",
    "                rewards=np.array(rewards),\n",
    "                next_states=np.array(next_states)\n",
    "            ))\n",
    "        return paths\n",
    "\n",
    "    \n",
    "    def render_policy(self):\n",
    "        render_policy(self.env,self.policy.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) REPS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REPS(RLModel):\n",
    "    def __init__(self, env, p=3, N=100,K=50,eta=0.1):\n",
    "        RLModel.__init__(self, env)\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.eta = eta\n",
    "        self.moving_rewards = []\n",
    "    \n",
    "    def compute_new_policy(self, eta, policy, phi, theta, samples):\n",
    "        log_new_pi = np.zeros((policy.n_states,policy.n_actions))\n",
    "        A = np.zeros((policy.n_states,policy.n_actions))\n",
    "        counter = np.zeros((policy.n_states,policy.n_actions))\n",
    "        nb_samples = 0\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            rewards = samples[i]['rewards']\n",
    "            next_states = samples[i]['next_states']\n",
    "\n",
    "            for j in range(len(states)):\n",
    "                A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "                counter[states[j],actions[j]] += 1\n",
    "                nb_samples += 1\n",
    "        for s in range(env.n_states):\n",
    "            for a in range(env.n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    A[s,a] /= counter[s,a]\n",
    "        for s in range(policy.n_states):\n",
    "            for a in range(policy.n_actions):\n",
    "                argexpo = np.zeros(policy.n_actions)\n",
    "                if policy.pi[s,a] == 0:\n",
    "                    log_new_pi[s,a] = -float('inf')\n",
    "                else:\n",
    "                    for b in range(policy.n_actions):\n",
    "                        argexpo[b] = np.log(policy.pi[s,b]+0.0001) + eta * A[s,b]\n",
    "                    maxi = np.max(argexpo)\n",
    "                    log_new_pi[s,a] = argexpo[a] - np.log(np.sum(np.exp(argexpo - maxi))) - maxi\n",
    "        return(Policy(np.exp(log_new_pi)))\n",
    "\n",
    "\n",
    "    def g(self, theta, eta, phi, samples):\n",
    "        res = 0\n",
    "        A = np.zeros((env.n_states,env.n_actions))\n",
    "        counter = np.zeros((env.n_states,env.n_actions))\n",
    "        nb_samples = 0\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            rewards = samples[i]['rewards']\n",
    "            next_states = samples[i]['next_states']\n",
    "\n",
    "            for j in range(len(states)):\n",
    "                A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "                counter[states[j],actions[j]] += 1\n",
    "                nb_samples += 1\n",
    "        for s in range(env.n_states):\n",
    "            for a in range(env.n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    A[s,a] /= counter[s,a]\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            for j in range(len(states)):\n",
    "                res += np.exp(eta*A[states[j],actions[j]])\n",
    "        res /= nb_samples\n",
    "        return (np.log(res)/eta)\n",
    "\n",
    "    def Dg(self, theta, eta, phi, samples):\n",
    "        n_states,p = np.shape(phi)\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        A = np.zeros((env.n_states,env.n_actions))\n",
    "        D = np.zeros((env.n_states,env.n_actions,p))\n",
    "        counter = np.zeros((env.n_states,env.n_actions))\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            rewards = samples[i]['rewards']\n",
    "            next_states = samples[i]['next_states']\n",
    "\n",
    "            for j in range(len(states)):\n",
    "                A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "                D[states[j],actions[j],:] += phi[next_states[j],:] - phi[states[j],:]\n",
    "                counter[states[j],actions[j]] += 1\n",
    "        for s in range(env.n_states):\n",
    "            for a in range(env.n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    A[s,a] /= counter[s,a]\n",
    "        for s in range(env.n_states):\n",
    "            for a in range(env.n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    D[s,a,:] /= counter[s,a]\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            for j in range(len(states)):\n",
    "                numerator += np.exp(eta*A[states[j],actions[j]]) * D[states[j],actions[j]]\n",
    "                denominator += np.exp(eta*A[states[j],actions[j]])\n",
    "        return ((1/eta) * numerator / denominator)\n",
    "\n",
    "    def compute_phi(self,p):\n",
    "        phi = np.zeros((self.env.n_states,p))\n",
    "        for k in range(self.env.n_states):\n",
    "            phi[k,:] = [k,k**2,np.log(k+1)]\n",
    "        return phi\n",
    "\n",
    "    def policy_update(self):\n",
    "        \"\"\"Relative Entropy Policy Search using Mirror Descent\"\"\"\n",
    "        p = 3    \n",
    "        # initialization of the distribution\n",
    "        pi = self.initialize_pi()\n",
    "        policy = Policy(pi)\n",
    "        #Tmax =  -100*np.log(10e-6)/(1-env.gamma)\n",
    "        T = 100\n",
    "        theta = [0 for i in range(p)]\n",
    "        phi = self.compute_phi(p)\n",
    "        \n",
    "        for k in tqdm(range(self.K), desc=\"Iterating REPS algorithm...\"):\n",
    "            ##### SAMPLING\n",
    "            samples = self.collect_episodes(policy=policy,horizon=T,n_episodes=self.N)\n",
    "\n",
    "            #### OPTIMIZE\n",
    "            theta = opt.fmin_bfgs(self.g,x0=theta,fprime=self.Dg,args=(self.eta,phi,samples), disp=0)\n",
    "\n",
    "            #### COMPUTE THE NEW POLICY\n",
    "            policy = self.compute_new_policy(self.eta,policy,phi,theta,samples) \n",
    "            \n",
    "            \n",
    "        self.policy = policy\n",
    "        self.theta = theta\n",
    "        self.phi = phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPS_model = REPS(env,K=100)\n",
    "REPS_model.policy_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_moving_reward = REPS_model.moving_rewards\n",
    "plt.plot(np.arange(len(avg_moving_reward)), avg_moving_reward)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Total moving reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPS_model.render_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) TRPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRPO(RLModel):\n",
    "    def __init__(self, env, K=200, N = 100, eta=0.1):\n",
    "        RLModel.__init__(self, env)\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.eta = eta\n",
    "        self.moving_rewards = []\n",
    "\n",
    "    def compute_Q(self, samples, Q):\n",
    "        n_states,n_actions = np.shape(Q)\n",
    "        counter = np.zeros((n_states,n_actions))\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            rewards = samples[i]['rewards']\n",
    "            next_states = samples[i]['next_states']\n",
    "\n",
    "            cumulated_rwd = 0\n",
    "            for j in range(len(states)):\n",
    "                t = len(states) -1 - j\n",
    "                cumulated_rwd = self.env.gamma * cumulated_rwd + rewards[t]\n",
    "                Q[states[t],actions[t]] += cumulated_rwd\n",
    "                counter[states[t],actions[t]] += 1\n",
    "\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    Q[s,a] /= counter[s,a]\n",
    "        return Q\n",
    "\n",
    "\n",
    "    def compute_value_function(self, Q, pi):\n",
    "        n_states,n_actions = np.shape(Q)\n",
    "        V = np.zeros(n_states)\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                V[s] += pi[s,a] * Q[s,a]\n",
    "        return V\n",
    "\n",
    "    def compute_advantage_function(self, pi, V, samples):\n",
    "        n_states, n_actions = np.shape(pi)\n",
    "        A = np.zeros((n_states,n_actions))\n",
    "        counter = np.zeros((n_states,n_actions))\n",
    "\n",
    "        for i in range(len(samples)):\n",
    "            states = samples[i]['states']\n",
    "            actions = samples[i]['actions']\n",
    "            rewards = samples[i]['rewards']\n",
    "            next_states = samples[i]['next_states']\n",
    "\n",
    "            for j in range(len(states)):\n",
    "                A[states[j],actions[j]] += rewards[j] + V[next_states[j]] - V[states[j]]\n",
    "                counter[states[j],actions[j]] += 1\n",
    "\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                if counter[s,a]!=0:\n",
    "                    A[s,a] /= counter[s,a]\n",
    "        return A\n",
    "\n",
    "    def update_pi(self, pi, A):\n",
    "        n_states,n_actions = np.shape(pi)\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                pi[s,a] *= np.exp(self.eta * A[s,a]) \n",
    "            pi[s,:] /= np.sum(pi[s,:])\n",
    "        return(pi)\n",
    "\n",
    "\n",
    "    def policy_update(self):\n",
    "        pi = self.initialize_pi()\n",
    "        A = np.ones((env.n_states,env.n_actions))\n",
    "        Q = np.ones((env.n_states,env.n_actions))\n",
    "        V = np.ones(env.n_states)\n",
    "        T = 100\n",
    "        for k in tqdm(range(self.K), desc=\"Iterating TRPO algorithm...\"):\n",
    "            policy = Policy(pi)\n",
    "            ##### SAMPLING\n",
    "            samples = self.collect_episodes(policy=policy,horizon=T,n_episodes=self.N)  \n",
    "\n",
    "            #### COMPUTE Q FUNCTION\n",
    "            Q = self.compute_Q(samples,Q)\n",
    "\n",
    "            #### COMPUTE VALUE FUNCTION\n",
    "            V = self.compute_value_function(Q,pi)\n",
    "\n",
    "            #### COMPUTE ADVANTAGE FUNCTION\n",
    "            A = self.compute_advantage_function(pi,V,samples)\n",
    "\n",
    "            #### COMPUTE THE NEW POLICY\n",
    "            pi = self.update_pi(pi, A)  \n",
    "            \n",
    "        self.policy = Policy(pi)\n",
    "        self.A = A\n",
    "        self.V = V\n",
    "        self.Q = Q\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRPO_model = TRPO(env)\n",
    "TRPO_model.policy_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_moving_reward = TRPO_model.moving_rewards\n",
    "plt.plot(np.arange(len(avg_moving_reward)), avg_moving_reward)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Total moving reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(M,t=0):\n",
    "    d,q = np.shape(M)\n",
    "    for i in range(d):\n",
    "        for j in range(q):\n",
    "            M[i,j] = max(M[i,j],t)\n",
    "    return M\n",
    "    \n",
    "\n",
    "def nmf_admm_KL(V,W,H,rho,N):\n",
    "    t_begin = time.time()\n",
    "    objectif = np.zeros(N)\n",
    "    times = np.zeros(N)\n",
    "    eps = 1e-5\n",
    "    \n",
    "    m,n = np.shape(V)\n",
    "    _,k = np.shape(W)\n",
    "        \n",
    "    X = np.dot(W,H)\n",
    "    Wp = W\n",
    "    Hp = H\n",
    "    alphaX = np.zeros(np.shape(X))\n",
    "    alphaW = np.zeros(np.shape(W))\n",
    "    alphaH = np.zeros(np.shape(H))\n",
    "    \n",
    "    for i in range(N):\n",
    "        # update H\n",
    "        H = np.dot(np.linalg.inv(np.dot(np.transpose(W),W)+np.eye(k)),np.dot(np.transpose(W),X)\n",
    "                   + Hp + (1/rho)*( np.dot(np.transpose(W),alphaX)-alphaH ) )\n",
    "        \n",
    "        # update W\n",
    "        A = np.dot(H,np.transpose(H)) + np.eye(k)\n",
    "        B = np.dot(H,np.transpose(X)) + np.transpose(Wp) + (1/rho)*(np.dot(H,np.transpose(alphaX))-np.transpose(alphaW) )\n",
    "        W = np.transpose( np.dot( np.linalg.inv(A) , B))\n",
    "        \n",
    "        # update X\n",
    "        b = rho * np.dot(W,H) - alphaX - 1\n",
    "        X = (b + np.sqrt(b**2 + 4 *rho*V))/(2*rho)\n",
    "        \n",
    "        # update for H+ and W+\n",
    "        Hp = threshold(H + (1/rho)*alphaH,0)\n",
    "        Wp = threshold(W + (1/rho)*alphaW,0)\n",
    "        \n",
    "        # update dual variables\n",
    "        alphaX += rho*(X-np.dot(W,H))\n",
    "        alphaH += rho*(H-Hp)\n",
    "        alphaW += rho*(W-Wp)\n",
    "        \n",
    "        objectif[i] = np.sum(-V*(np.log((np.dot(Wp,Hp)+eps) / (V+eps))+1) + np.dot(Wp,Hp))\n",
    "        times[i] = time.time() - t_begin\n",
    "\n",
    "    return(Wp, Hp, objectif, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) MUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_mua_KL(V, W, H, N):\n",
    "    t_begin = time.time()\n",
    "    objectif = np.zeros(N)\n",
    "    times = np.zeros(N)\n",
    "    eps = 1e-5\n",
    "    \n",
    "    m,n = np.shape(V)\n",
    "    _,k = np.shape(W)\n",
    "    \n",
    "    for i in range(N):\n",
    "        Hsumtemp = np.sum(H,axis=1)+eps\n",
    "        Hsumtemp = Hsumtemp.reshape(1,-1)\n",
    "        W = W * (np.dot(V / (np.dot(W,H)+eps) , np.transpose(H))) / np.tile( Hsumtemp, (m,1))\n",
    "        \n",
    "        Wsumtemp = np.sum(W,axis=0)+eps\n",
    "        Wsumtemp = Wsumtemp.reshape(-1,1)\n",
    "        H = H * (np.dot( np.transpose(W), V / (np.dot(W,H)+eps))) / np.tile( Wsumtemp, (1,n))\n",
    "        \n",
    "        objectif[i] = np.sum(-V*(np.log((np.dot(W,H)+eps) / (V+eps))+1) + np.dot(W,H))\n",
    "        times[i] = time.time() - t_begin\n",
    "    return(W, H, objectif, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) FPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_fpa_KL(V, W, H, N, ND):\n",
    "    \n",
    "    # ND represents the number of iteration for each ND problem\n",
    "    t_begin = time.time()\n",
    "    objectif = []\n",
    "    times = []\n",
    "    \n",
    "    m,n = np.shape(V)\n",
    "    r,_ = np.shape(H)\n",
    "    eps = 1e-7\n",
    "    Wb = W\n",
    "    Wold = W\n",
    "    Hb = H\n",
    "    Hold = H\n",
    "    C = - V / np.dot(W,H)\n",
    "    P = -np.dot(np.transpose(W),C) * np.tile( np.sum(W,axis=0).reshape(-1,1),(1,n))\n",
    "    MP = np.max(P,axis=0)\n",
    "    C = C * np.tile( (1/MP).reshape(1,-1),(m,1))\n",
    "    \n",
    "    for i in range(int(N/ND)):\n",
    "        sigma = np.sqrt(n/r) * np.sum(H) / (np.linalg.norm(W) * np.sum(V,axis=0))\n",
    "        tau = np.sqrt(r/n) * np.sum(V,axis=0) / (np.linalg.norm(W) * np.sum(W))\n",
    "        \n",
    "        for j in range(ND):\n",
    "            C += np.dot(W,Hb) * np.tile(sigma.reshape(1,-1),(m,1))\n",
    "            C = 0.5 * C - 0.5 * np.sqrt(C**2 + V * 4 * np.tile(sigma.reshape(1,-1),(m,1)))\n",
    "            H = threshold( H- np.dot(np.transpose(W),C+1) * np.tile(tau.reshape(1,-1),(r,1)))\n",
    "            Hb = 2*H - Hold\n",
    "            Hold = H\n",
    "    \n",
    "        sigma = np.sqrt(m/r) * np.sum(H) / (np.linalg.norm(W) * np.sum(V,axis=1))\n",
    "        tau = np.sqrt(r/m) * np.sum(V,axis=1) / (np.linalg.norm(H) * np.sum(H))\n",
    "        \n",
    "        for j in range(ND):\n",
    "            C += np.dot(Wb,H) * np.tile(sigma.reshape(-1,1),(1,n))\n",
    "            C = 0.5 * C -0.5 * np.sqrt(C**2 + V * 4 * np.tile(sigma.reshape(-1,1),(1,n)))\n",
    "            W = threshold( W - np.dot(C+1,np.transpose(H)) * np.tile(tau.reshape(-1,1),(1,r)))\n",
    "            Wb = 2*W - Wold\n",
    "            Wold = W\n",
    "    \n",
    "        for l in range(ND):\n",
    "            objectif.append(np.sum(-V*(np.log((np.dot(W,H)+eps) / (V+eps))+1) + np.dot(W,H)))\n",
    "        times.append(time.time() - t_begin)\n",
    "    return(W, H, np.array(objectif), np.array(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, r = 200, 500, 10\n",
    "N = 2000\n",
    "\n",
    "np.random.seed(0)\n",
    "# construction of the matrices\n",
    "W = np.abs(np.random.rand(n,r))\n",
    "H = np.abs(np.random.rand(r,m))\n",
    "V = np.dot(W,H)\n",
    "\n",
    "# initialization\n",
    "Wini = np.random.rand(n,r)\n",
    "Hini = np.random.rand(r,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADMM\n",
    "rho = 4\n",
    "W1,H1,objectifs1,times1 = nmf_admm_KL(V, Wini, Hini, rho, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MUA\n",
    "W2, H2, objectifs2, times2 = nmf_mua_KL(V, Wini, Hini, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FPA\n",
    "ND = \n",
    "W3, H3, objectifs3, times3 = nmf_fpa_KL(V, Wini, Hini, N, ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(np.log10(objectifs1),label='ADMM')\n",
    "plt.plot(np.log10(objectifs2),label='MUA')\n",
    "plt.plot(np.log10(objectifs3),label='FPA')\n",
    "plt.legend()\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log( Objectif = KL divergence between V and W*H )')\n",
    "plt.savefig('nmf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
